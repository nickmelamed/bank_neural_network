{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba652776-bb62-4ca1-a82d-7184ca6cae1f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc5f9f5-8da0-42ce-b469-34cc624a9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim \n",
    "from imblearn import over_sampling\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a78dce-0ee6-49d2-925d-54e8eb42618b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303f6020-c87d-4e56-81ce-78a4077c400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/bank-additional-full.csv\", delimiter = \";\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d234e-ba62-467f-a1f6-276ecbdb7397",
   "metadata": {},
   "source": [
    "The description of the columns can be found at the UCI Machine Learning Repository, linked [here](https://archive.ics.uci.edu/dataset/222/bank+marketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9cdd6e-9607-428e-829a-f195b2803c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de3c15-b5b2-4671-82d6-93fb532c83b1",
   "metadata": {},
   "source": [
    "For this particular analysis, I am going to ignore economic factors, as I will take the simplifying assumption that the majority of people who are in this campaign are not making decisions based on economic factors like the consumer price index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce26f816-4819-4add-bf86-73467efec00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome   y  \n",
       "0   may         mon       261         1    999         0  nonexistent  no  \n",
       "1   may         mon       149         1    999         0  nonexistent  no  \n",
       "2   may         mon       226         1    999         0  nonexistent  no  \n",
       "3   may         mon       151         1    999         0  nonexistent  no  \n",
       "4   may         mon       307         1    999         0  nonexistent  no  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.columns[~df.columns.isin(['emp.var.rate', 'cons.price.idx','cons.conf.idx', 'euribor3m', 'nr.employed'])]]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf261b37-5288-480a-bc99-04bb9a0afe8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         32588\n",
       "unknown     8597\n",
       "yes            3\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7808cb1a-d7f8-4908-ba4f-c68913ee27db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes        21576\n",
       "no         18622\n",
       "unknown      990\n",
       "Name: housing, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['housing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b452bb3-d02b-4a40-8c20-e2438ac5c482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         33950\n",
       "yes         6248\n",
       "unknown      990\n",
       "Name: loan, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loan'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9036b73-5650-4e4a-84ef-3c05b73f5dff",
   "metadata": {},
   "source": [
    "As we can see from above, the number of customers who have defaulted on previous loans is relatively low. So, to avoid dealing with the unknown values, we will make the assumption that the vast majority of people have not defaulted and therefore this column does not provide us any predictive information. \n",
    "\n",
    "We will also drop the unknowns from people who have taken housing or personal loans, as we have a sufficient sample size without the unknowns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07781a83-1e03-4e5c-93bb-216d46aa5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['default'])\n",
    "\n",
    "df = df[(df['housing'] != 'unknown') & (df['loan'] != 'unknown')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5e3f1-68b0-431a-9400-b0f66dc1cd56",
   "metadata": {},
   "source": [
    "In order to run our neural network, we have to make all of our variables numeric. We do so by turning any categorical variables into dummy variables (1 = variable is true, 0 = false), and, since the binary variables are stored as yes/no variables, we will convert those into 1/0 values as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6da9a5b-2421-40e7-a67b-e25a9de72830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>job: admin.</th>\n",
       "      <th>job: blue-collar</th>\n",
       "      <th>...</th>\n",
       "      <th>month: oct</th>\n",
       "      <th>month: sep</th>\n",
       "      <th>day_of_week: fri</th>\n",
       "      <th>day_of_week: mon</th>\n",
       "      <th>day_of_week: thu</th>\n",
       "      <th>day_of_week: tue</th>\n",
       "      <th>day_of_week: wed</th>\n",
       "      <th>poutcome: failure</th>\n",
       "      <th>poutcome: nonexistent</th>\n",
       "      <th>poutcome: success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  housing  loan  duration  campaign  pdays  previous  y  job: admin.  \\\n",
       "0   56        0     0       261         1    999         0  0            0   \n",
       "1   57        0     0       149         1    999         0  0            0   \n",
       "2   37        1     0       226         1    999         0  0            0   \n",
       "3   40        0     0       151         1    999         0  0            1   \n",
       "4   56        0     1       307         1    999         0  0            0   \n",
       "\n",
       "   job: blue-collar  ...  month: oct  month: sep  day_of_week: fri  \\\n",
       "0                 0  ...           0           0                 0   \n",
       "1                 0  ...           0           0                 0   \n",
       "2                 0  ...           0           0                 0   \n",
       "3                 0  ...           0           0                 0   \n",
       "4                 0  ...           0           0                 0   \n",
       "\n",
       "   day_of_week: mon  day_of_week: thu  day_of_week: tue  day_of_week: wed  \\\n",
       "0                 1                 0                 0                 0   \n",
       "1                 1                 0                 0                 0   \n",
       "2                 1                 0                 0                 0   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 1                 0                 0                 0   \n",
       "\n",
       "   poutcome: failure  poutcome: nonexistent  poutcome: success  \n",
       "0                  0                      1                  0  \n",
       "1                  0                      1                  0  \n",
       "2                  0                      1                  0  \n",
       "3                  0                      1                  0  \n",
       "4                  0                      1                  0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting categorical variables into dummies\n",
    "\n",
    "df_dummy = pd.get_dummies(df, columns = ['job', 'marital', 'education', 'contact', 'month', 'day_of_week', 'poutcome'], prefix_sep = ': ')\n",
    "\n",
    "# turning y/n variables into 1/0\n",
    "\n",
    "df_dummy['housing'] = np.where(df['housing'].values == 'yes', 1, 0)\n",
    "df_dummy['loan'] = np.where(df['loan'].values == 'yes', 1, 0)\n",
    "df_dummy['y'] = np.where(df['y'].values == 'yes', 1, 0)\n",
    "\n",
    "df_dummy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5547b18-d530-4dbc-8968-13f77f852ad8",
   "metadata": {},
   "source": [
    "## Building the Basic Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd5c7e-1166-4d4b-a45c-adb4a6e2e8f3",
   "metadata": {},
   "source": [
    "For any model building, we want to ensure our model is not trained on the entirety of our dataset. Otherwise, we would have no data to test the model on, and run the risk of overtraining. I have decided to use Scikit-Learn to split the dataset into 70% training data, 30% testing data. An 80-20 split is another popular option but I prefer to have more testing data to ensure the model is even less susceptible to the overtraining problem.\n",
    "\n",
    "We make sure our outcome variable, y (whether or not the client subscribed to the term deposit, the goal of the campaign), is separated from our other predictor variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "139b4ff9-3256-4f47-961d-7b8f247a4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummy[df_dummy.columns[~df_dummy.columns.isin(['y'])]]\n",
    "y = df_dummy['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932eacd3-4074-4d79-b3e9-e3847942e8c1",
   "metadata": {},
   "source": [
    "### Training the Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e7f0d3-d68c-46cb-9a9c-f5561beaf4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensor(df, outcome):\n",
    "    ''' Converts a df into a numpy array and then a Tensor with dtype float32 to be used in a PyTorch model \n",
    "        \n",
    "        Inputs: \n",
    "            df (DataFrame): Input dataframe to be converted\n",
    "            outcome (Boolean): Whether or not the df is an outcome vector; if it is, must be converted to 1D tensor for processing\n",
    "        \n",
    "        Outputs:\n",
    "            as_tensor (Tensor): dtype float32 Tensor; use float32 as it is the input type for torch.nn neural networks\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    df_np = df.to_numpy() # convert to numpy so we can use torch.from_numpy method\n",
    "    if outcome: \n",
    "        return torch.from_numpy(df_np).reshape(-1, 1).to(torch.float32) # reshape makes the Tensor 1D if it is an outcome vector\n",
    "    return torch.from_numpy(df_np).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c2ef25c-e58d-4f78-8db8-d37f9a6800f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training data into tensors\n",
    "\n",
    "X_train_tensor = df_to_tensor(X_train, outcome = False)\n",
    "y_train_tensor = df_to_tensor(y_train, outcome = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021dffef-232c-4c4e-b3cd-7666953e4a1e",
   "metadata": {},
   "source": [
    "For our model, we will be using PyTorch's Sequential Neural Network (SNN), as it allows us to utilize multiple layers in a sequential order. Being able to apply multiple activation functions to our model allows for more thorough training of the model. \n",
    "\n",
    "For this given model, we use two Linear Modules as our hidden layers to perform linear transformations (for ease of calculation), along with the ReLU activation function for both layers. Our output layer makes use of a Sigmoid function, as this maps our transformed data to [0,1] for classification. \n",
    "\n",
    "With regards to the number of neurons we use for our hidden layers, many rules of thumb have been proposed. Some have suggested that the number of neurons should be $\\frac{2}{3}$ that of the output layer, some have suggested no more than 2x the input layer. We will use K-fold Cross Validation to determine which option, including a 3rd possibility of the middle of the road of the two (1.3x input layer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17f126c9-3bcb-4a65-a9f8-41f4f57b0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the number of output neurons for our hidden layers \n",
    "\n",
    "N_i = len(X_train.columns) # number of features represents the number of the nodes in the input layer\n",
    "\n",
    "N_h = int(1.3 * N_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8ab26524-4bb4-4404-9e94-2c73a25d11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model using PyTorch\n",
    "\n",
    "def sequential_NN(multiplier, N_i = len(X.columns)):\n",
    "    ''' Create a Sequental NN from PyTorch with two linear hidden layers and a sigmoid activation function\n",
    "    \n",
    "        Inputs:\n",
    "            multiplier (float): what we multiply the number of input neurons by to get the number of neurons for the hidden layers\n",
    "            N_i (int): The number of input neurons, which we take as the number of features in the model \n",
    "        \n",
    "        Outputs:\n",
    "            model (nn.Sequential): Sequential NN with each hidden layer having the calculated number of neurons\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    N_h = int(N_i * multiplier) \n",
    "                                 \n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(N_i, N_h),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(N_h, N_i),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(N_i, 1),\n",
    "    nn.Sigmoid())\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d3057-e25f-4ecf-9ebf-70b940c5e1cc",
   "metadata": {},
   "source": [
    "Since we are using a binary classifier (either the campaign is successful or it isn't), we use Binary Cross Entropy loss as it measures the error in mislabeled outcomes for a single outcome vector. We use the Adam optimizer due to its ability to have quick convergence and deal with sparse gradients, which we may deal with as a result of having a lot of dummy variables. \n",
    "\n",
    "As for how we go about training the model, we use 100 epochs, which represents the number of times the entire dataset is run through the model. 100 is a fairly traditional number based on the existing NN literature. For batch size, which is the size of the sample that is run through the model at a time, as we are using batch gradient descent, powers of 2 are common, with 32 being considered the upper limit for batch size. We will use this upper limit as we are dealing with a high number of samples (N = ~40,000). Our learning rate of 0.001 for the Adam optimizer is widely recognized as the ideal learning rate, so we will not change this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8d23459b-2b03-4915-a1fb-ff10d5692cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd():\n",
    "    '''Trains a model through mini-batch Stochastic Gradient Descent (SGD)\n",
    "    \n",
    "        Inputs: \n",
    "            model (torch.nn): A PyTorch Neural Network \n",
    "            loss (nn.BCELoss()): Binary Cross-Entropy Loss function from PyTorch\n",
    "            alpha (float): learning rate for optimizer \n",
    "            optimizer (optim.Adam): Adam optimizer for performing backward iteration, steps, and gradient calculation\n",
    "            X (tensor): training data feature tensor\n",
    "            y (tensor): training data outcome tensor \n",
    "            num_epochs (int): Number of times the entirety of the model is run through SGD \n",
    "            batch_size (int): Number of inputs processed in single iteration of SGD \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    model = neural\n",
    "    loss_fn = nn.BCELoss()\n",
    "    alpha = 0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    X = X_train_tensor\n",
    "    y = y_train_tensor\n",
    "    n_epochs = 100\n",
    "    batch_size = 32\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(0, len(X_train_tensor), batch_size):\n",
    "            Xbatch = X_train_tensor[i:i+batch_size]\n",
    "            y_pred = model(Xbatch)\n",
    "            ybatch = y_train_tensor[i:i+batch_size]\n",
    "            loss = loss_fn(y_pred, ybatch)\n",
    "            optimizer.zero_grad() # resets the gradient for faster performance \n",
    "            loss.backward() # computes the gradient for the given batch \n",
    "            optimizer.step() # updates parameters based on gradient calculation \n",
    "        print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ab9b5ebd-885b-4324-9a5c-46bd9d31d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.2160571813583374\n",
      "Finished epoch 1, latest loss 0.21437910199165344\n",
      "Finished epoch 2, latest loss 0.19906504452228546\n",
      "Finished epoch 3, latest loss 0.21520960330963135\n",
      "Finished epoch 4, latest loss 0.22045573592185974\n",
      "Finished epoch 5, latest loss 0.21404850482940674\n",
      "Finished epoch 6, latest loss 0.20876367390155792\n",
      "Finished epoch 7, latest loss 0.20605015754699707\n",
      "Finished epoch 8, latest loss 0.20433136820793152\n",
      "Finished epoch 9, latest loss 0.19889554381370544\n",
      "Finished epoch 10, latest loss 0.19855527579784393\n",
      "Finished epoch 11, latest loss 0.20169496536254883\n",
      "Finished epoch 12, latest loss 0.19745559990406036\n",
      "Finished epoch 13, latest loss 0.19541020691394806\n",
      "Finished epoch 14, latest loss 0.19591735303401947\n",
      "Finished epoch 15, latest loss 0.19069263339042664\n",
      "Finished epoch 16, latest loss 0.19934764504432678\n",
      "Finished epoch 17, latest loss 0.18870408833026886\n",
      "Finished epoch 18, latest loss 0.19255760312080383\n",
      "Finished epoch 19, latest loss 0.19471211731433868\n",
      "Finished epoch 20, latest loss 0.1886456161737442\n",
      "Finished epoch 21, latest loss 0.18387074768543243\n",
      "Finished epoch 22, latest loss 0.18173936009407043\n",
      "Finished epoch 23, latest loss 0.1816207617521286\n",
      "Finished epoch 24, latest loss 0.1895921528339386\n",
      "Finished epoch 25, latest loss 0.17882412672042847\n",
      "Finished epoch 26, latest loss 0.17684154212474823\n",
      "Finished epoch 27, latest loss 0.18216711282730103\n",
      "Finished epoch 28, latest loss 0.17824169993400574\n",
      "Finished epoch 29, latest loss 0.18170849978923798\n",
      "Finished epoch 30, latest loss 0.185727059841156\n",
      "Finished epoch 31, latest loss 0.17468534409999847\n",
      "Finished epoch 32, latest loss 0.176164448261261\n",
      "Finished epoch 33, latest loss 0.18558654189109802\n",
      "Finished epoch 34, latest loss 0.18589720129966736\n",
      "Finished epoch 35, latest loss 0.18252287805080414\n",
      "Finished epoch 36, latest loss 0.18026259541511536\n",
      "Finished epoch 37, latest loss 0.18459075689315796\n",
      "Finished epoch 38, latest loss 0.17672209441661835\n",
      "Finished epoch 39, latest loss 0.18111233413219452\n",
      "Finished epoch 40, latest loss 0.18497687578201294\n",
      "Finished epoch 41, latest loss 0.17814961075782776\n",
      "Finished epoch 42, latest loss 0.18192240595817566\n",
      "Finished epoch 43, latest loss 0.18950310349464417\n",
      "Finished epoch 44, latest loss 0.18544402718544006\n",
      "Finished epoch 45, latest loss 0.17835447192192078\n",
      "Finished epoch 46, latest loss 0.18286754190921783\n",
      "Finished epoch 47, latest loss 0.18054114282131195\n",
      "Finished epoch 48, latest loss 0.1794787347316742\n",
      "Finished epoch 49, latest loss 0.19001534581184387\n",
      "Finished epoch 50, latest loss 0.17866817116737366\n",
      "Finished epoch 51, latest loss 0.19347789883613586\n",
      "Finished epoch 52, latest loss 0.17950020730495453\n",
      "Finished epoch 53, latest loss 0.1810634881258011\n",
      "Finished epoch 54, latest loss 0.18059168756008148\n",
      "Finished epoch 55, latest loss 0.1955033838748932\n",
      "Finished epoch 56, latest loss 0.17908719182014465\n",
      "Finished epoch 57, latest loss 0.18010565638542175\n",
      "Finished epoch 58, latest loss 0.1882357895374298\n",
      "Finished epoch 59, latest loss 0.18279704451560974\n",
      "Finished epoch 60, latest loss 0.19310882687568665\n",
      "Finished epoch 61, latest loss 0.18550299108028412\n",
      "Finished epoch 62, latest loss 0.18071770668029785\n",
      "Finished epoch 63, latest loss 0.18282870948314667\n",
      "Finished epoch 64, latest loss 0.17915508151054382\n",
      "Finished epoch 65, latest loss 0.1816726177930832\n",
      "Finished epoch 66, latest loss 0.1721770465373993\n",
      "Finished epoch 67, latest loss 0.18767708539962769\n",
      "Finished epoch 68, latest loss 0.1797824203968048\n",
      "Finished epoch 69, latest loss 0.18263977766036987\n",
      "Finished epoch 70, latest loss 0.18223340809345245\n",
      "Finished epoch 71, latest loss 0.17440831661224365\n",
      "Finished epoch 72, latest loss 0.18736431002616882\n",
      "Finished epoch 73, latest loss 0.18688443303108215\n",
      "Finished epoch 74, latest loss 0.17462822794914246\n",
      "Finished epoch 75, latest loss 0.1864466369152069\n",
      "Finished epoch 76, latest loss 0.17943748831748962\n",
      "Finished epoch 77, latest loss 0.17980945110321045\n",
      "Finished epoch 78, latest loss 0.1863398402929306\n",
      "Finished epoch 79, latest loss 0.1703631430864334\n",
      "Finished epoch 80, latest loss 0.18025994300842285\n",
      "Finished epoch 81, latest loss 0.18544124066829681\n",
      "Finished epoch 82, latest loss 0.17464704811573029\n",
      "Finished epoch 83, latest loss 0.17146530747413635\n",
      "Finished epoch 84, latest loss 0.18324550986289978\n",
      "Finished epoch 85, latest loss 0.18024249374866486\n",
      "Finished epoch 86, latest loss 0.16745392978191376\n",
      "Finished epoch 87, latest loss 0.1825762689113617\n",
      "Finished epoch 88, latest loss 0.16869118809700012\n",
      "Finished epoch 89, latest loss 0.1749085634946823\n",
      "Finished epoch 90, latest loss 0.17128577828407288\n",
      "Finished epoch 91, latest loss 0.17592501640319824\n",
      "Finished epoch 92, latest loss 0.16727331280708313\n",
      "Finished epoch 93, latest loss 0.16761109232902527\n",
      "Finished epoch 94, latest loss 0.1719568520784378\n",
      "Finished epoch 95, latest loss 0.1734994351863861\n",
      "Finished epoch 96, latest loss 0.16691400110721588\n",
      "Finished epoch 97, latest loss 0.16483727097511292\n",
      "Finished epoch 98, latest loss 0.16661348938941956\n",
      "Finished epoch 99, latest loss 0.17139451205730438\n"
     ]
    }
   ],
   "source": [
    "neural = sequential_NN(1.3)\n",
    "train_sgd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad09cd-3bed-4553-9875-5665b84b2426",
   "metadata": {},
   "source": [
    "### Training Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba24e94-a394-4494-99fa-43e9994002a2",
   "metadata": {},
   "source": [
    "We compute the training accuracy of our model, which is the percentage of correctly labelled outcomes, to determine how well it classifies our desired outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b689a067-7121-4dac-9fd6-c2e8b4a8cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(X):\n",
    "    ''' Runs given data through our model, returning the predicted classes\n",
    "    \n",
    "        Inputs:\n",
    "            X (tensor): tensor containing input data for the model \n",
    "        \n",
    "        Outputs:\n",
    "            classifications (tensor): tensor containing the predicted classes for X \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    with torch.no_grad(): # we don't want to update our gradient; we just want to see the already classified data\n",
    "        predicted_probabilities = model(X)\n",
    "\n",
    "    classifications = predicted_probabilities.round() # probabilities >= 0.5 get rounded to 1, under to 0 \n",
    "    return classifications\n",
    "\n",
    "def accuracy(classifications, y):\n",
    "    ''' Calculate the accuracy, or the percentage of correct predictions, of the model \n",
    "    \n",
    "        Inputs:\n",
    "            classifications (tensor): tensor of predicted classes (output of classify_data)\n",
    "            y (tensor): tensor of true classes\n",
    "        \n",
    "        Outputs: \n",
    "            accuracy (float): accuracy of the predictions as a percentage\n",
    "        \n",
    "    '''\n",
    "    accuracy = (classifications == y).float().mean()\n",
    "    return round(float(accuracy)*100, 2) # have to convert accuracy from Tensor to float to convert as percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f5859a00-d9bd-4379-9450-f8cf975a8721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 91.45%\n"
     ]
    }
   ],
   "source": [
    "train_classifications = classify_data(X_train_tensor)\n",
    "    \n",
    "train_accuracy = accuracy(train_classifications, y_train_tensor)\n",
    "print(f\"Training Accuracy: {train_accuracy}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca026bf8-2d21-4743-aa74-92d071f9633a",
   "metadata": {},
   "source": [
    "This is a very encouraging training accuracy! However, it is quite high and could be a result of overtraining our data, or it could be the result of us having a class imbalance.\n",
    "\n",
    "Let us examine the class imbalance possibility: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bf3b83a4-9815-4832-9fe9-c719ffa76528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Positives: 4533\n",
      "Number of Negatives: 35665\n",
      "Ratio of Positives to Negatives: 0.13\n"
     ]
    }
   ],
   "source": [
    "num_pos = sum(y) # we are dealing with 0s and 1s!\n",
    "num_neg = len(y) - sum(y)\n",
    "print(f\"Number of Positives: {num_pos}\")\n",
    "print(f\"Number of Negatives: {num_neg}\")\n",
    "print(f\"Ratio of Positives to Negatives: {round(num_pos / num_neg, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec99b4f-feb7-4398-989e-c641d25a5444",
   "metadata": {},
   "source": [
    "We do have a rather large imbalance in class size, which could be artificially inflating our accuracy measure. Considering the size imbalance is large, but not to the point where we have too small of a sample size for either class, we will proceed forward with some other metrics to gain more insight into our model's performance on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bd8ee905-61b4-4c2d-afec-acc83630b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defininig functions to calculate performance metrics \n",
    "\n",
    "def calculate_pos_neg(predictions, original):\n",
    "    ''' Calculates TP, TN, FP, FN of given Tensors\n",
    "    \n",
    "        Inputs:\n",
    "            predictions (tensor): tensor of predicted class probabilities\n",
    "            original (tensor): original outcome/class assignments\n",
    "        \n",
    "        Outputs:\n",
    "            results (list): List of TP, TN, FP, and FN \n",
    "    '''\n",
    "    classifications = predictions.round() # turns probabilities into 0/1 classifications \n",
    "    \n",
    "    combined = torch.stack((classifications, original), 0) # combined[0] is classifications, combined[1] is y_tensor\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i in range(len(classifications)):\n",
    "        if combined[0][i] == combined[1][i]:\n",
    "            if combined[0][i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        if combined[0][i] != combined[1][i]:\n",
    "            if combined[0][i] == 1:\n",
    "                fp += 1\n",
    "            else: \n",
    "                fn += 1\n",
    "                \n",
    "    return [tp, fp, tn, fn]\n",
    "\n",
    "def calculate_metrics(frequencies):\n",
    "    ''' Calculates Precision, Recall, F1 Score, Specificity, True Negative Rate, and False Negative Rate\n",
    "    \n",
    "        Inputs:\n",
    "            frequencies (list): List consisting of TP, TN, FP, FN (all integers, outputted from calcualte_pos_neg)\n",
    "        \n",
    "        Outputs:\n",
    "            results (list): List of Precision, Recall, F1 Score, Specificity, True Negative Rate, and False Negative Rate\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    tp = frequencies[0]\n",
    "    fp = frequencies[1]\n",
    "    tn = frequencies[2]\n",
    "    fn = frequencies[3]\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    specificity = fp / (fp + tn)\n",
    "    tnr = 1 - specificity # TNR and Specificity are complements \n",
    "    fnr = 1 - recall # FNR and Recall are complements \n",
    "    \n",
    "    return [precision, recall, f1, specificity, tnr, fnr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d6b11998-dcf0-4f18-8800-9a6d44f77c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision: 64.7%\n",
      "Training Recall: 48.79%\n",
      "Training F1 Score: 0.56\n",
      "Training Specificity: 3.35%\n",
      "Training True Negative Rate (TNR): 96.65%\n",
      "Training False Negative Rate (FNR): 51.21%\n"
     ]
    }
   ],
   "source": [
    "training_metrics = calculate_metrics(calculate_pos_neg(y_pred_train, y_train_tensor))\n",
    "\n",
    "\n",
    "print(f\"Training Precision: {round(training_metrics[0] * 100, 2)}%\")\n",
    "print(f\"Training Recall: {round(training_metrics[1] * 100, 2)}%\")\n",
    "print(f\"Training F1 Score: {round(training_metrics[2], 2)}\")\n",
    "print(f\"Training Specificity: {round(training_metrics[3] * 100, 2)}%\")\n",
    "print(f\"Training True Negative Rate (TNR): {round(training_metrics[4] * 100, 2)}%\")\n",
    "print(f\"Training False Negative Rate (FNR): {round(training_metrics[5] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2416ec-59e0-4165-8116-a08ecaf4f230",
   "metadata": {},
   "source": [
    "As we can see, with these other metrics, our model's accuracy is not reflective of what we would want to see. The training model is exceptionally good at identifying negatives correctly (TNR), but only decent at identifying positives correctly (Precision). \n",
    "\n",
    "Our F1 score, which is the weighted mean of precision and recall, suggests that our model is average at best at predicting positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c0f761-2e41-4a00-9c4e-c69551b0c448",
   "metadata": {},
   "source": [
    "### Fitting Model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686bf440-cb75-45eb-9457-54f9beee6815",
   "metadata": {},
   "source": [
    "To address the overfitting concern, let us use our test data to assess the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c156a2a6-deb3-489f-adb7-b55252519cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting test data to Tensors\n",
    "\n",
    "X_test_tensor = df_to_tensor(X_test, outcome = False)\n",
    "y_test_tensor = df_to_tensor(y_test, outcome = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b37ef33-ad2a-4700-9185-79b52421dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.78%\n"
     ]
    }
   ],
   "source": [
    "# computing test accuracy \n",
    "\n",
    "test_classifications = classify_data(X_test_tensor)\n",
    "    \n",
    "test_accuracy = accuracy(test_classifications, y_test_tensor)\n",
    "print(f\"Test Accuracy: {test_accuracy}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce464b40-9cc4-43e6-912e-eee54cf8d1e5",
   "metadata": {},
   "source": [
    "We have a similarly high test data accuracy, so let's see if our imbalance problems carry over: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44017008-13db-47c7-965c-2122d455ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Precision: 63.75%\n",
      "Testing Recall: 45.7%\n",
      "Testing F1 Score: 0.53\n",
      "Testing Specificity: 3.37%\n",
      "Testing True Negative Rate (TNR): 96.63%\n",
      "Testing False Negative Rate (FNR): 54.3%\n"
     ]
    }
   ],
   "source": [
    "testing_metrics = calculate_metrics(calculate_pos_neg(y_pred_test, y_test_tensor))\n",
    "\n",
    "\n",
    "print(f\"Testing Precision: {round(testing_metrics[0] * 100, 2)}%\")\n",
    "print(f\"Testing Recall: {round(testing_metrics[1] * 100, 2)}%\")\n",
    "print(f\"Testing F1 Score: {round(testing_metrics[2], 2)}\")\n",
    "print(f\"Testing Specificity: {round(testing_metrics[3] * 100, 2)}%\")\n",
    "print(f\"Testing True Negative Rate (TNR): {round(testing_metrics[4] * 100, 2)}%\")\n",
    "print(f\"Testing False Negative Rate (FNR): {round(testing_metrics[5] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fefede8-de1a-4ac9-bd93-54c9965eff72",
   "metadata": {},
   "source": [
    "We perform roughly the same compared to our training model. \n",
    "\n",
    "Is there a way for us to improve model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e66c544-0a02-492b-9f9a-a44fd47e38fc",
   "metadata": {},
   "source": [
    "## Solution 1: Fixing the Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c0db2-ae9f-403e-8c73-35033bba83bb",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98a1fc-4b00-470f-b0a7-25b9ec74e1a1",
   "metadata": {},
   "source": [
    "SMOTE, or Synthetic Minority Oversampling Technique, is a class imbalance correction technique. SMOTE works to correct class imbalance by synthetically creating new minority class datapoints, which avoids the hiccups involved with random techniques like over or undersampling. \n",
    "\n",
    "There are some limitations, like trouble translating to higher dimensions, or the possibility of adding noise to the data because it does not consider the majority class when creating synthetic minority class data points.\n",
    "\n",
    "First, let's generate the new, more balanced classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f34c15e-3679-46ba-862d-5d2873c56bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Number of Positives: 4533 vs. New Number of Positives: 10699\n",
      "Original Number of Negatives: 35665 vs. New Number of Negatives: 35665\n"
     ]
    }
   ],
   "source": [
    "oversample = over_sampling.SMOTE(sampling_strategy = 0.3)\n",
    "X_bal, y_bal = oversample.fit_resample(X, y)\n",
    "\n",
    "bal_num_pos = sum(y_bal)\n",
    "bal_num_neg = len(y_bal) - bal_num_pos\n",
    "\n",
    "print(f\"Original Number of Positives: {num_pos} vs. New Number of Positives: {bal_num_pos}\")\n",
    "print(f\"Original Number of Negatives: {num_neg} vs. New Number of Negatives: {bal_num_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45437d1b-b052-4f32-8426-748dd752f760",
   "metadata": {},
   "source": [
    "All we have done is inflate the number of positives so that they now constitute roughly 30% of our dataset. Let us see if this creates any improvement in model performance: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623461b3-9a74-47f2-9571-6135cb658957",
   "metadata": {},
   "source": [
    "### Training Model Post-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc6a8f0e-6411-41db-8157-d6bcd7dbc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal_train, X_bal_test, y_bal_train, y_bal_test = train_test_split(X_bal, y_bal, random_state=0, train_size = .70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9281d598-f243-4a18-bc0e-397394c63d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting balanced training data into tensors\n",
    "\n",
    "X_bal_train_tensor = df_to_tensor(X_bal_train, outcome = False)\n",
    "y_bal_train_tensor = df_to_tensor(y_bal_train, outcome = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13e48143-3e97-457d-9ffb-745b2ab41db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.5528285503387451\n",
      "Finished epoch 1, latest loss 0.4085456430912018\n",
      "Finished epoch 2, latest loss 0.37239256501197815\n",
      "Finished epoch 3, latest loss 0.2951275110244751\n",
      "Finished epoch 4, latest loss 0.26278969645500183\n",
      "Finished epoch 5, latest loss 0.24875782430171967\n",
      "Finished epoch 6, latest loss 0.22522373497486115\n",
      "Finished epoch 7, latest loss 0.19584278762340546\n",
      "Finished epoch 8, latest loss 0.15925084054470062\n",
      "Finished epoch 9, latest loss 0.14214853942394257\n",
      "Finished epoch 10, latest loss 0.12505365908145905\n",
      "Finished epoch 11, latest loss 0.10558471828699112\n",
      "Finished epoch 12, latest loss 0.11162086576223373\n",
      "Finished epoch 13, latest loss 0.10797242075204849\n",
      "Finished epoch 14, latest loss 0.09547233581542969\n",
      "Finished epoch 15, latest loss 0.07443880289793015\n",
      "Finished epoch 16, latest loss 0.07245483249425888\n",
      "Finished epoch 17, latest loss 0.08304374665021896\n",
      "Finished epoch 18, latest loss 0.08149172365665436\n",
      "Finished epoch 19, latest loss 0.07781846821308136\n",
      "Finished epoch 20, latest loss 0.0670102909207344\n",
      "Finished epoch 21, latest loss 0.08074528723955154\n",
      "Finished epoch 22, latest loss 0.07214035838842392\n",
      "Finished epoch 23, latest loss 0.07351169735193253\n",
      "Finished epoch 24, latest loss 0.08943220227956772\n",
      "Finished epoch 25, latest loss 0.06176702678203583\n",
      "Finished epoch 26, latest loss 0.073835089802742\n",
      "Finished epoch 27, latest loss 0.0636124238371849\n",
      "Finished epoch 28, latest loss 0.07008571177721024\n",
      "Finished epoch 29, latest loss 0.0697421059012413\n",
      "Finished epoch 30, latest loss 0.08199803531169891\n",
      "Finished epoch 31, latest loss 0.0611906498670578\n",
      "Finished epoch 32, latest loss 0.06918372213840485\n",
      "Finished epoch 33, latest loss 0.0852249339222908\n",
      "Finished epoch 34, latest loss 0.06705418229103088\n",
      "Finished epoch 35, latest loss 0.07992839068174362\n",
      "Finished epoch 36, latest loss 0.06711796671152115\n",
      "Finished epoch 37, latest loss 0.06230861321091652\n",
      "Finished epoch 38, latest loss 0.041341740638017654\n",
      "Finished epoch 39, latest loss 0.04456115886569023\n",
      "Finished epoch 40, latest loss 0.05035359784960747\n",
      "Finished epoch 41, latest loss 0.08466703444719315\n",
      "Finished epoch 42, latest loss 0.070810966193676\n",
      "Finished epoch 43, latest loss 0.053931158035993576\n",
      "Finished epoch 44, latest loss 0.0657045915722847\n",
      "Finished epoch 45, latest loss 0.05994463339447975\n",
      "Finished epoch 46, latest loss 0.05461772903800011\n",
      "Finished epoch 47, latest loss 0.07766091078519821\n",
      "Finished epoch 48, latest loss 0.045021042227745056\n",
      "Finished epoch 49, latest loss 0.0503276102244854\n",
      "Finished epoch 50, latest loss 0.06062248721718788\n",
      "Finished epoch 51, latest loss 0.048260435461997986\n",
      "Finished epoch 52, latest loss 0.06657339632511139\n",
      "Finished epoch 53, latest loss 0.04944591596722603\n",
      "Finished epoch 54, latest loss 0.044346924871206284\n",
      "Finished epoch 55, latest loss 0.0411938801407814\n",
      "Finished epoch 56, latest loss 0.05013865604996681\n",
      "Finished epoch 57, latest loss 0.043916989117860794\n",
      "Finished epoch 58, latest loss 0.04270321503281593\n",
      "Finished epoch 59, latest loss 0.04162830486893654\n",
      "Finished epoch 60, latest loss 0.056777630001306534\n",
      "Finished epoch 61, latest loss 0.036602847278118134\n",
      "Finished epoch 62, latest loss 0.04053790867328644\n",
      "Finished epoch 63, latest loss 0.04047560319304466\n",
      "Finished epoch 64, latest loss 0.04031522199511528\n",
      "Finished epoch 65, latest loss 0.0457155704498291\n",
      "Finished epoch 66, latest loss 0.04775281250476837\n",
      "Finished epoch 67, latest loss 0.04012362286448479\n",
      "Finished epoch 68, latest loss 0.052081432193517685\n",
      "Finished epoch 69, latest loss 0.04892539605498314\n",
      "Finished epoch 70, latest loss 0.05016559362411499\n",
      "Finished epoch 71, latest loss 0.048705700784921646\n",
      "Finished epoch 72, latest loss 0.04159091040492058\n",
      "Finished epoch 73, latest loss 0.06810341030359268\n",
      "Finished epoch 74, latest loss 0.040742166340351105\n",
      "Finished epoch 75, latest loss 0.046475257724523544\n",
      "Finished epoch 76, latest loss 0.03927917033433914\n",
      "Finished epoch 77, latest loss 0.050506383180618286\n",
      "Finished epoch 78, latest loss 0.04174792766571045\n",
      "Finished epoch 79, latest loss 0.045396849513053894\n",
      "Finished epoch 80, latest loss 0.03517657890915871\n",
      "Finished epoch 81, latest loss 0.05158674716949463\n",
      "Finished epoch 82, latest loss 0.03657311573624611\n",
      "Finished epoch 83, latest loss 0.03327406570315361\n",
      "Finished epoch 84, latest loss 0.04157617315649986\n",
      "Finished epoch 85, latest loss 0.04945070669054985\n",
      "Finished epoch 86, latest loss 0.055232200771570206\n",
      "Finished epoch 87, latest loss 0.05089172348380089\n",
      "Finished epoch 88, latest loss 0.03463376685976982\n",
      "Finished epoch 89, latest loss 0.028015315532684326\n",
      "Finished epoch 90, latest loss 0.03377984091639519\n",
      "Finished epoch 91, latest loss 0.04768471047282219\n",
      "Finished epoch 92, latest loss 0.04726581275463104\n",
      "Finished epoch 93, latest loss 0.11281478404998779\n",
      "Finished epoch 94, latest loss 0.03925536572933197\n",
      "Finished epoch 95, latest loss 0.060529351234436035\n",
      "Finished epoch 96, latest loss 0.0448455847799778\n",
      "Finished epoch 97, latest loss 0.03945915773510933\n",
      "Finished epoch 98, latest loss 0.04267806187272072\n",
      "Finished epoch 99, latest loss 0.03668125346302986\n"
     ]
    }
   ],
   "source": [
    "train_sgd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82192d45-9a34-4d2d-af3b-ecc6f65d5597",
   "metadata": {},
   "source": [
    "### Training Performance w/ SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40483105-f880-4b63-ae10-cbb17114ab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 92.73%\n"
     ]
    }
   ],
   "source": [
    "bal_train_classifications = classify_data(X_bal_train_tensor)\n",
    "    \n",
    "bal_train_accuracy = accuracy(bal_train_classifications, y_bal_train_tensor)\n",
    "print(f\"Balanced Training Accuracy: {bal_train_accuracy}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c7f1b-266b-4d4d-af61-794555653ec8",
   "metadata": {},
   "source": [
    "We observe a similar level of accuracy to our previous attempts, but given our lower loss during the training phases, I would believe this will result in better performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "25468f76-0191-45ed-9db5-474bc3ae39f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Training Precision: 89.6%\n",
      "Balanced Training Recall: 77.42%\n",
      "Balanced Training F1 Score: 0.83\n",
      "Balanced Training Specificity: 2.69%\n",
      "Balanced Training True Negative Rate (TNR): 97.31%\n",
      "Balanced Training False Negative Rate (FNR): 22.58%\n"
     ]
    }
   ],
   "source": [
    "bal_training_metrics = calculate_metrics(calculate_pos_neg(y_bal_train_pred, y_bal_train_tensor))\n",
    "\n",
    "\n",
    "print(f\"Balanced Training Precision: {round(bal_training_metrics[0] * 100, 2)}%\")\n",
    "print(f\"Balanced Training Recall: {round(bal_training_metrics[1] * 100, 2)}%\")\n",
    "print(f\"Balanced Training F1 Score: {round(bal_training_metrics[2], 2)}\")\n",
    "print(f\"Balanced Training Specificity: {round(bal_training_metrics[3] * 100, 2)}%\")\n",
    "print(f\"Balanced Training True Negative Rate (TNR): {round(bal_training_metrics[4] * 100, 2)}%\")\n",
    "print(f\"Balanced Training False Negative Rate (FNR): {round(bal_training_metrics[5] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bf740-7ab0-408e-82fa-dc21deb4d339",
   "metadata": {},
   "source": [
    "We see a dramatic improvement in our metrics! We have a very strong positive predictor now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c848e1f6-9abb-499b-9ade-33122764ec0d",
   "metadata": {},
   "source": [
    "Let's make sure this carries over to our testing data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb31003-ff63-4c3d-aec7-37ec993d6743",
   "metadata": {},
   "source": [
    "### Testing Model Post-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "98bd44bc-a621-4d4e-b8ea-1411125cbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal_test_tensor = df_to_tensor(X_bal_test, outcome = False)\n",
    "y_bal_test_tensor = df_to_tensor(y_bal_test, outcome = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "561c2188-9165-4453-a973-b2a8e8c97f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 92.03%\n"
     ]
    }
   ],
   "source": [
    "bal_test_classifications = classify_data(X_bal_test_tensor)\n",
    "    \n",
    "bal_test_accuracy = accuracy(bal_train_classifications, y_bal_test_tensor)\n",
    "print(f\"Balanced Test Accuracy: {train_accuracy}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a04ce5-6fb5-4c30-a339-89617115a897",
   "metadata": {},
   "source": [
    "We have a similarly high training accuracy, but let's see if this carries over to the other metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b9652afb-657c-4250-9cfb-0e4b9199a70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Testing Precision: 88.14%\n",
      "Balanced Testing Recall: 75.74%\n",
      "Balanced Testing F1 Score: 0.81\n",
      "Balanced Testing Specificity: 3.07%\n",
      "Balanced Testing True Negative Rate (TNR): 96.93%\n",
      "Balanced Testing False Negative Rate (FNR): 24.26%\n"
     ]
    }
   ],
   "source": [
    "bal_testing_metrics = calculate_metrics(calculate_pos_neg(y_bal_test_pred, y_bal_test_tensor))\n",
    "\n",
    "\n",
    "print(f\"Balanced Test Precision: {round(bal_testing_metrics[0] * 100, 2)}%\")\n",
    "print(f\"Balanced Test Recall: {round(bal_testing_metrics[1] * 100, 2)}%\")\n",
    "print(f\"Balanced Test F1 Score: {round(bal_testing_metrics[2], 2)}\")\n",
    "print(f\"Balanced Test Specificity: {round(bal_testing_metrics[3] * 100, 2)}%\")\n",
    "print(f\"Balanced Test True Negative Rate (TNR): {round(bal_testing_metrics[4] * 100, 2)}%\")\n",
    "print(f\"Balanced Test False Negative Rate (FNR): {round(bal_testing_metrics[5] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853a338-a752-40be-8a72-d84c14ec62ec",
   "metadata": {},
   "source": [
    "Our performance on the test set is rouhgly the same as our training data! We have a strong classifier on our hands! \n",
    "\n",
    "Can we make it even better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46226596-55a9-4237-9c88-682f262a1434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
