{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba652776-bb62-4ca1-a82d-7184ca6cae1f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc5f9f5-8da0-42ce-b469-34cc624a9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim \n",
    "from imblearn import over_sampling\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a78dce-0ee6-49d2-925d-54e8eb42618b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303f6020-c87d-4e56-81ce-78a4077c400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/bank-additional-full.csv\", delimiter = \";\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d234e-ba62-467f-a1f6-276ecbdb7397",
   "metadata": {},
   "source": [
    "The description of the columns can be found at the UCI Machine Learning Repository, linked [here](https://archive.ics.uci.edu/dataset/222/bank+marketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9cdd6e-9607-428e-829a-f195b2803c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de3c15-b5b2-4671-82d6-93fb532c83b1",
   "metadata": {},
   "source": [
    "For this particular analysis, I am going to ignore economic factors, as I will take the simplifying assumption that the majority of people who are in this campaign are not making decisions based on economic factors like the consumer price index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce26f816-4819-4add-bf86-73467efec00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome   y  \n",
       "0   may         mon       261         1    999         0  nonexistent  no  \n",
       "1   may         mon       149         1    999         0  nonexistent  no  \n",
       "2   may         mon       226         1    999         0  nonexistent  no  \n",
       "3   may         mon       151         1    999         0  nonexistent  no  \n",
       "4   may         mon       307         1    999         0  nonexistent  no  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.columns[~df.columns.isin(['emp.var.rate', 'cons.price.idx','cons.conf.idx', 'euribor3m', 'nr.employed'])]]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf261b37-5288-480a-bc99-04bb9a0afe8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         32588\n",
       "unknown     8597\n",
       "yes            3\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7808cb1a-d7f8-4908-ba4f-c68913ee27db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes        21576\n",
       "no         18622\n",
       "unknown      990\n",
       "Name: housing, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['housing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b452bb3-d02b-4a40-8c20-e2438ac5c482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         33950\n",
       "yes         6248\n",
       "unknown      990\n",
       "Name: loan, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loan'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9036b73-5650-4e4a-84ef-3c05b73f5dff",
   "metadata": {},
   "source": [
    "As we can see from above, the number of customers who have defaulted on previous loans is relatively low. So, to avoid dealing with the unknown values, we will make the assumption that the vast majority of people have not defaulted and therefore this column does not provide us any predictive information. \n",
    "\n",
    "We will also drop the unknowns from people who have taken housing or personal loans, as we have a sufficient sample size without the unknowns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07781a83-1e03-4e5c-93bb-216d46aa5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['default'])\n",
    "\n",
    "df = df[(df['housing'] != 'unknown') & (df['loan'] != 'unknown')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5e3f1-68b0-431a-9400-b0f66dc1cd56",
   "metadata": {},
   "source": [
    "In order to run our neural network, we have to make all of our variables numeric. We do so by turning any categorical variables into dummy variables (1 = variable is true, 0 = false), and, since the binary variables are stored as yes/no variables, we will convert those into 1/0 values as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6da9a5b-2421-40e7-a67b-e25a9de72830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>job: admin.</th>\n",
       "      <th>job: blue-collar</th>\n",
       "      <th>...</th>\n",
       "      <th>month: oct</th>\n",
       "      <th>month: sep</th>\n",
       "      <th>day_of_week: fri</th>\n",
       "      <th>day_of_week: mon</th>\n",
       "      <th>day_of_week: thu</th>\n",
       "      <th>day_of_week: tue</th>\n",
       "      <th>day_of_week: wed</th>\n",
       "      <th>poutcome: failure</th>\n",
       "      <th>poutcome: nonexistent</th>\n",
       "      <th>poutcome: success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  housing  loan  duration  campaign  pdays  previous  y  job: admin.  \\\n",
       "0   56        0     0       261         1    999         0  0            0   \n",
       "1   57        0     0       149         1    999         0  0            0   \n",
       "2   37        1     0       226         1    999         0  0            0   \n",
       "3   40        0     0       151         1    999         0  0            1   \n",
       "4   56        0     1       307         1    999         0  0            0   \n",
       "\n",
       "   job: blue-collar  ...  month: oct  month: sep  day_of_week: fri  \\\n",
       "0                 0  ...           0           0                 0   \n",
       "1                 0  ...           0           0                 0   \n",
       "2                 0  ...           0           0                 0   \n",
       "3                 0  ...           0           0                 0   \n",
       "4                 0  ...           0           0                 0   \n",
       "\n",
       "   day_of_week: mon  day_of_week: thu  day_of_week: tue  day_of_week: wed  \\\n",
       "0                 1                 0                 0                 0   \n",
       "1                 1                 0                 0                 0   \n",
       "2                 1                 0                 0                 0   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 1                 0                 0                 0   \n",
       "\n",
       "   poutcome: failure  poutcome: nonexistent  poutcome: success  \n",
       "0                  0                      1                  0  \n",
       "1                  0                      1                  0  \n",
       "2                  0                      1                  0  \n",
       "3                  0                      1                  0  \n",
       "4                  0                      1                  0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting categorical variables into dummies\n",
    "\n",
    "df_dummy = pd.get_dummies(df, columns = ['job', 'marital', 'education', 'contact', 'month', 'day_of_week', 'poutcome'], prefix_sep = ': ')\n",
    "\n",
    "# turning y/n variables into 1/0\n",
    "\n",
    "df_dummy['housing'] = np.where(df['housing'].values == 'yes', 1, 0)\n",
    "df_dummy['loan'] = np.where(df['loan'].values == 'yes', 1, 0)\n",
    "df_dummy['y'] = np.where(df['y'].values == 'yes', 1, 0)\n",
    "\n",
    "df_dummy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5547b18-d530-4dbc-8968-13f77f852ad8",
   "metadata": {},
   "source": [
    "## Building the Basic Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd5c7e-1166-4d4b-a45c-adb4a6e2e8f3",
   "metadata": {},
   "source": [
    "For any model building, we want to ensure our model is not trained on the entirety of our dataset. Otherwise, we would have no data to test the model on, and run the risk of overtraining. I have decided to use Scikit-Learn to split the dataset into 70% training data, 30% testing data. An 80-20 split is another popular option but I prefer to have more testing data to ensure the model is even less susceptible to the overtraining problem.\n",
    "\n",
    "We make sure our outcome variable, y (whether or not the client subscribed to the term deposit, the goal of the campaign), is separated from our other predictor variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "139b4ff9-3256-4f47-961d-7b8f247a4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummy[df_dummy.columns[~df_dummy.columns.isin(['y'])]]\n",
    "y = df_dummy['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932eacd3-4074-4d79-b3e9-e3847942e8c1",
   "metadata": {},
   "source": [
    "### Training the Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e7f0d3-d68c-46cb-9a9c-f5561beaf4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensor(df, outcome):\n",
    "    ''' Converts a df into a numpy array and then a Tensor with dtype float32 to be used in a PyTorch model \n",
    "        \n",
    "        Params: \n",
    "            df (DataFrame): Input dataframe to be converted\n",
    "            outcome (Boolean): Whether or not the df is an outcome vector; if it is, must be converted to 1D tensor for processing\n",
    "        \n",
    "        Returns:\n",
    "            as_tensor (Tensor): dtype float32 Tensor; use float32 as it is the input type for torch.nn neural networks\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    df_np = df.to_numpy() # convert to numpy so we can use torch.from_numpy method\n",
    "    if outcome: \n",
    "        return torch.from_numpy(df_np).reshape(-1, 1).to(torch.float32) # reshape makes the Tensor 1D if it is an outcome vector\n",
    "    return torch.from_numpy(df_np).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c2ef25c-e58d-4f78-8db8-d37f9a6800f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training data into tensors\n",
    "\n",
    "X_train_tensor = df_to_tensor(X_train, outcome = False)\n",
    "y_train_tensor = df_to_tensor(y_train, outcome = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021dffef-232c-4c4e-b3cd-7666953e4a1e",
   "metadata": {},
   "source": [
    "For our model, we will be using PyTorch's Sequential Neural Network (SNN), as it allows us to utilize multiple layers in a sequential order. Being able to apply multiple activation functions to our model allows for more thorough training of the model. \n",
    "\n",
    "For this given model, we use two Linear Modules as our hidden layers to perform linear transformations (for ease of calculation), along with the ReLU activation function for both layers. Our output layer makes use of a Sigmoid function, as this maps our transformed data to [0,1] for classification. \n",
    "\n",
    "With regards to the number of neurons we use for our hidden layers, many rules of thumb have been proposed. Some have suggested that the number of neurons should be $\\frac{2}{3}$ that of the output layer, some have suggested no more than 2x the input layer, so we will split the middle and use 1.3x. This is an arbitrary decision, but since there is not much literature for guidance beyond these softer suggestions, we will make do with this in lieu of extensive guess and check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17f126c9-3bcb-4a65-a9f8-41f4f57b0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the number of output neurons for our hidden layers \n",
    "\n",
    "N_i = len(X_train.columns) # number of features represents the number of the nodes in the input layer\n",
    "\n",
    "N_h = int(1.3 * N_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ab26524-4bb4-4404-9e94-2c73a25d11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model using PyTorch\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(N_i, N_h),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(N_h, N_i),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(N_i, 1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d3057-e25f-4ecf-9ebf-70b940c5e1cc",
   "metadata": {},
   "source": [
    "Since we are using a binary classifier (either the campaign is successful or it isn't), we use Binary Cross Entropy loss as it measures the error in mislabeled outcomes for a single outcome vector. We use the Adam optimizer due to its ability to have quick convergence and deal with sparse gradients, which we may deal with as a result of having a lot of dummy variables. \n",
    "\n",
    "As for how we go about training the model, we use 100 epochs, which represents the number of times the entire dataset is run through the model. 100 is a fairly traditional number based on the existing NN literature. For batch size, which is the size of the sample that is run through the model at a time, as we are using batch gradient descent, powers of 2 are common, with 32 being considered the upper limit for batch size. We will use this upper limit as we are dealing with a high number of samples (N = ~40,000). Our learning rate of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e330c0-b3e2-4cd6-a2f4-9dfdd606aad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.22431285679340363\n",
      "Finished epoch 1, latest loss 0.2086951732635498\n",
      "Finished epoch 2, latest loss 0.2068432867527008\n",
      "Finished epoch 3, latest loss 0.21198216080665588\n",
      "Finished epoch 4, latest loss 0.20626583695411682\n",
      "Finished epoch 5, latest loss 0.18865451216697693\n",
      "Finished epoch 6, latest loss 0.1815384328365326\n",
      "Finished epoch 7, latest loss 0.17915308475494385\n",
      "Finished epoch 8, latest loss 0.17947454750537872\n",
      "Finished epoch 9, latest loss 0.18734335899353027\n",
      "Finished epoch 10, latest loss 0.18332123756408691\n",
      "Finished epoch 11, latest loss 0.183085098862648\n",
      "Finished epoch 12, latest loss 0.17581342160701752\n",
      "Finished epoch 13, latest loss 0.18078556656837463\n",
      "Finished epoch 14, latest loss 0.1804172694683075\n",
      "Finished epoch 15, latest loss 0.17048503458499908\n",
      "Finished epoch 16, latest loss 0.16576209664344788\n",
      "Finished epoch 17, latest loss 0.16001704335212708\n",
      "Finished epoch 18, latest loss 0.15929800271987915\n",
      "Finished epoch 19, latest loss 0.17186003923416138\n",
      "Finished epoch 20, latest loss 0.16529244184494019\n",
      "Finished epoch 21, latest loss 0.16283969581127167\n",
      "Finished epoch 22, latest loss 0.1648164689540863\n",
      "Finished epoch 23, latest loss 0.1731863021850586\n",
      "Finished epoch 24, latest loss 0.16384510695934296\n",
      "Finished epoch 25, latest loss 0.1712096929550171\n",
      "Finished epoch 26, latest loss 0.16171297430992126\n",
      "Finished epoch 27, latest loss 0.15814781188964844\n",
      "Finished epoch 28, latest loss 0.16260652244091034\n",
      "Finished epoch 29, latest loss 0.162704199552536\n",
      "Finished epoch 30, latest loss 0.1663469821214676\n",
      "Finished epoch 31, latest loss 0.1635282337665558\n",
      "Finished epoch 32, latest loss 0.17820234596729279\n",
      "Finished epoch 33, latest loss 0.1714859902858734\n",
      "Finished epoch 34, latest loss 0.1683351695537567\n",
      "Finished epoch 35, latest loss 0.16906967759132385\n",
      "Finished epoch 36, latest loss 0.16675162315368652\n",
      "Finished epoch 37, latest loss 0.16649067401885986\n",
      "Finished epoch 38, latest loss 0.16952930390834808\n",
      "Finished epoch 39, latest loss 0.17399363219738007\n",
      "Finished epoch 40, latest loss 0.16040527820587158\n",
      "Finished epoch 41, latest loss 0.16204993426799774\n",
      "Finished epoch 42, latest loss 0.15901398658752441\n",
      "Finished epoch 43, latest loss 0.15912418067455292\n",
      "Finished epoch 44, latest loss 0.15593066811561584\n",
      "Finished epoch 45, latest loss 0.16591110825538635\n",
      "Finished epoch 46, latest loss 0.16813598573207855\n",
      "Finished epoch 47, latest loss 0.1666596233844757\n",
      "Finished epoch 48, latest loss 0.17128516733646393\n",
      "Finished epoch 49, latest loss 0.16357213258743286\n",
      "Finished epoch 50, latest loss 0.16545379161834717\n",
      "Finished epoch 51, latest loss 0.16134443879127502\n",
      "Finished epoch 52, latest loss 0.16965481638908386\n",
      "Finished epoch 53, latest loss 0.1635603904724121\n",
      "Finished epoch 54, latest loss 0.16176797449588776\n",
      "Finished epoch 55, latest loss 0.17765095829963684\n",
      "Finished epoch 56, latest loss 0.16836610436439514\n",
      "Finished epoch 57, latest loss 0.17909224331378937\n",
      "Finished epoch 58, latest loss 0.17025823891162872\n",
      "Finished epoch 59, latest loss 0.16894908249378204\n",
      "Finished epoch 60, latest loss 0.1677328646183014\n",
      "Finished epoch 61, latest loss 0.167706698179245\n",
      "Finished epoch 62, latest loss 0.163414865732193\n",
      "Finished epoch 63, latest loss 0.16097889840602875\n",
      "Finished epoch 64, latest loss 0.16951444745063782\n",
      "Finished epoch 65, latest loss 0.16070404648780823\n",
      "Finished epoch 66, latest loss 0.16588494181632996\n",
      "Finished epoch 67, latest loss 0.17111222445964813\n",
      "Finished epoch 68, latest loss 0.1652357280254364\n",
      "Finished epoch 69, latest loss 0.16712123155593872\n",
      "Finished epoch 70, latest loss 0.17401790618896484\n",
      "Finished epoch 71, latest loss 0.16339603066444397\n",
      "Finished epoch 72, latest loss 0.16129687428474426\n",
      "Finished epoch 73, latest loss 0.16543863713741302\n",
      "Finished epoch 74, latest loss 0.1599390208721161\n",
      "Finished epoch 75, latest loss 0.16574814915657043\n",
      "Finished epoch 76, latest loss 0.16712602972984314\n",
      "Finished epoch 77, latest loss 0.1617695391178131\n",
      "Finished epoch 78, latest loss 0.1674163043498993\n",
      "Finished epoch 79, latest loss 0.17080336809158325\n",
      "Finished epoch 80, latest loss 0.1672859638929367\n",
      "Finished epoch 81, latest loss 0.16063575446605682\n",
      "Finished epoch 82, latest loss 0.1635395884513855\n",
      "Finished epoch 83, latest loss 0.16421976685523987\n",
      "Finished epoch 84, latest loss 0.16266515851020813\n",
      "Finished epoch 85, latest loss 0.16256725788116455\n",
      "Finished epoch 86, latest loss 0.165991872549057\n",
      "Finished epoch 87, latest loss 0.1680862009525299\n",
      "Finished epoch 88, latest loss 0.16226737201213837\n",
      "Finished epoch 89, latest loss 0.1676587164402008\n",
      "Finished epoch 90, latest loss 0.16544319689273834\n",
      "Finished epoch 91, latest loss 0.16479060053825378\n",
      "Finished epoch 92, latest loss 0.16539250314235687\n",
      "Finished epoch 93, latest loss 0.16871681809425354\n",
      "Finished epoch 94, latest loss 0.16600313782691956\n",
      "Finished epoch 95, latest loss 0.16687510907649994\n",
      "Finished epoch 96, latest loss 0.16875402629375458\n",
      "Finished epoch 97, latest loss 0.1663917750120163\n",
      "Finished epoch 98, latest loss 0.16431187093257904\n",
      "Finished epoch 99, latest loss 0.16861993074417114\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        Xbatch = X_train_tensor[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y_train_tensor[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad() # resets the gradient for faster performance \n",
    "        loss.backward() # computes the gradient for the given batch \n",
    "        optimizer.step() # updates parameters based on gradient calculation \n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad09cd-3bed-4553-9875-5665b84b2426",
   "metadata": {},
   "source": [
    "### Training Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba24e94-a394-4494-99fa-43e9994002a2",
   "metadata": {},
   "source": [
    "We compute the training accuracy of our model, which is the percentage of correctly labelled outcomes, to determine how well it classifies our desired outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5859a00-d9bd-4379-9450-f8cf975a8721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 91.29%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # we don't want to update our gradient; we just want to see the already classified data\n",
    "    y_pred_train = model(X_train_tensor)\n",
    "\n",
    "train_classifications = y_pred_train.round()\n",
    "    \n",
    "train_accuracy = (train_classifications == y_train_tensor).float().mean()\n",
    "print(f\"Training Accuracy: {round(float(train_accuracy)*100, 2)}%\") # have to convert accuracy from Tensor to float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca026bf8-2d21-4743-aa74-92d071f9633a",
   "metadata": {},
   "source": [
    "This is a very encouraging training accuracy! However, it is quite high and could be a result of overtraining our data, or it could be the result of us having a class imbalance.\n",
    "\n",
    "Let us examine the class imbalance possibility: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf3b83a4-9815-4832-9fe9-c719ffa76528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Positives: 3148\n",
      "Number of Training Negatives: 24990\n",
      "Ratio of Positives to Negatives: 0.13\n"
     ]
    }
   ],
   "source": [
    "training_pos = len(torch.masked_select(y_train_tensor, y_train_tensor == 1))\n",
    "training_neg = len(torch.masked_select(y_train_tensor, y_train_tensor == 0))\n",
    "print(f\"Number of Training Positives: {training_pos}\")\n",
    "print(f\"Number of Training Negatives: {training_neg}\")\n",
    "print(f\"Ratio of Positives to Negatives: {round(training_pos / training_neg, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec99b4f-feb7-4398-989e-c641d25a5444",
   "metadata": {},
   "source": [
    "We do have a rather large imbalance in class size, which could be artificially inflating our accuracy measure. Considering the size imbalance is large, but not to the point where we have too small of a sample size for either class, we will proceed forward with some other metrics to gain more insight into our model's performance on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6b11998-dcf0-4f18-8800-9a6d44f77c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision: 64.7%\n",
      "Training Recall: 48.79%\n",
      "Training F1 Score: 0.56\n",
      "Training Specificity: 3.35%\n",
      "Training True Negative Rate (TNR): 96.65%\n",
      "Training False Negative Rate (FNR): 51.21%\n"
     ]
    }
   ],
   "source": [
    "def calculate_pos_neg(predictions, original):\n",
    "    ''' Calculates TP, TN, FP, FN of given Tensors\n",
    "    \n",
    "        Inputs:\n",
    "        predictions (tensor): tensor of predicted class probabilities\n",
    "        original (tensor): original outcome/class assignments\n",
    "        \n",
    "        Outputs:\n",
    "        results (list): List of TP, TN, FP, and FN \n",
    "    '''\n",
    "    classifications = predictions.round() # turns probabilities into 0/1 classifications \n",
    "    \n",
    "    combined = torch.stack((classifications, original), 0) # combined[0] is classifications, combined[1] is y_train_tensor\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i in range(len(classifications)):\n",
    "        if combined[0][i] == combined[1][i]:\n",
    "            if combined[0][i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        if combined[0][i] != combined[1][i]:\n",
    "            if combined[0][i] == 1:\n",
    "                fp += 1\n",
    "            else: \n",
    "                fn += 1\n",
    "                \n",
    "    return [tp, fp, tn, fn]\n",
    "\n",
    "train_metrics = calculate_pos_neg(y_pred_train, y_train_tensor)\n",
    "train_tp = train_metrics[0]\n",
    "train_fp = train_metrics[1]\n",
    "train_tn = train_metrics[2]\n",
    "train_fn = train_metrics[3]\n",
    "            \n",
    "train_precision = train_tp / (train_tp + train_fp)\n",
    "train_recall = train_tp / (train_tp + train_fn)\n",
    "train_f1 = (2 * train_precision * train_recall) / (train_precision + train_recall)\n",
    "train_specificity = train_fp / (train_fp + train_tn)\n",
    "train_tnr = train_tn / (train_tn + train_fp)\n",
    "train_fnr = train_fn / (train_fn + train_tp)\n",
    "\n",
    "print(f\"Training Precision: {round(train_precision * 100, 2)}%\")\n",
    "print(f\"Training Recall: {round(train_recall * 100, 2)}%\")\n",
    "print(f\"Training F1 Score: {round(train_f1, 2)}\")\n",
    "print(f\"Training Specificity: {round(train_specificity * 100, 2)}%\")\n",
    "print(f\"Training True Negative Rate (TNR): {round(train_tnr * 100, 2)}%\")\n",
    "print(f\"Training False Negative Rate (FNR): {round(train_fnr * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2416ec-59e0-4165-8116-a08ecaf4f230",
   "metadata": {},
   "source": [
    "As we can see, with these other metrics, our model's accuracy is not reflective of what we would want to see. The training model is exceptionally good at identifying negatives correctly (TNR), but only decent at identifying positives correctly (Precision). \n",
    "\n",
    "Our F1 score, which is the weighted mean of precision and recall, suggests that our model is average at best at predicting positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c0f761-2e41-4a00-9c4e-c69551b0c448",
   "metadata": {},
   "source": [
    "### Fitting Model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686bf440-cb75-45eb-9457-54f9beee6815",
   "metadata": {},
   "source": [
    "To address the overfitting concern, let us use our test data to assess the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c156a2a6-deb3-489f-adb7-b55252519cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting test data to Tensors\n",
    "\n",
    "X_test_tensor = df_to_tensor(X_test, outcome = False)\n",
    "y_test_tensor = df_to_tensor(y_test, outcome = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b37ef33-ad2a-4700-9185-79b52421dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.78%\n"
     ]
    }
   ],
   "source": [
    "# computing test accuracy \n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test_tensor)\n",
    "\n",
    "test_accuracy = (y_pred_test.round() == y_test_tensor).float().mean()\n",
    "print(f\"Test Accuracy: {round(float(test_accuracy)*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce464b40-9cc4-43e6-912e-eee54cf8d1e5",
   "metadata": {},
   "source": [
    "We have a similarly high test data accuracy, so let's examine the class balance here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "466210fd-bdcb-4f8f-8df3-ebed23a11394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Testing Positives: 1385\n",
      "Number of Testing Negatives: 10675\n",
      "Ratio of Positives to Negatives: 0.13\n"
     ]
    }
   ],
   "source": [
    "testing_pos = len(torch.masked_select(y_test_tensor, y_test_tensor == 1))\n",
    "testing_neg = len(torch.masked_select(y_test_tensor, y_test_tensor == 0))\n",
    "print(f\"Number of Testing Positives: {testing_pos}\")\n",
    "print(f\"Number of Testing Negatives: {testing_neg}\")\n",
    "print(f\"Ratio of Positives to Negatives: {round(testing_pos / testing_neg, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb871f-79cb-40fd-ab90-763a91623e19",
   "metadata": {},
   "source": [
    "Our class imbalance is roughly the same, so we would expect similar performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44017008-13db-47c7-965c-2122d455ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Precision: 63.75%\n",
      "Testing Recall: 45.7%\n",
      "Testing F1 Score: 0.53\n",
      "Testing Specificity: 3.37%\n",
      "Testing True Negative Rate (TNR): 96.63%\n",
      "Testing False Negative Rate (FNR): 54.3%\n"
     ]
    }
   ],
   "source": [
    "test_metrics = calculate_pos_neg(y_pred_test, y_test_tensor)\n",
    "test_tp = test_metrics[0]\n",
    "test_fp = test_metrics[1]\n",
    "test_tn = test_metrics[2]\n",
    "test_fn = test_metrics[3]\n",
    "            \n",
    "test_precision = test_tp / (test_tp + test_fp)\n",
    "test_recall = test_tp / (test_tp + test_fn)\n",
    "test_f1 = (2 * test_precision * test_recall) / (test_precision + test_recall)\n",
    "test_specificity = test_fp / (test_fp + test_tn)\n",
    "test_tnr = test_tn / (test_tn + test_fp)\n",
    "test_fnr = test_fn / (test_fn + test_tp)\n",
    "\n",
    "print(f\"Testing Precision: {round(test_precision * 100, 2)}%\")\n",
    "print(f\"Testing Recall: {round(test_recall * 100, 2)}%\")\n",
    "print(f\"Testing F1 Score: {round(test_f1, 2)}\")\n",
    "print(f\"Testing Specificity: {round(test_specificity * 100, 2)}%\")\n",
    "print(f\"Testing True Negative Rate (TNR): {round(test_tnr * 100, 2)}%\")\n",
    "print(f\"Testing False Negative Rate (FNR): {round(test_fnr * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fefede8-de1a-4ac9-bd93-54c9965eff72",
   "metadata": {},
   "source": [
    "We perform roughly the same compared to our training model. \n",
    "\n",
    "Is there a way for us to improve model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e66c544-0a02-492b-9f9a-a44fd47e38fc",
   "metadata": {},
   "source": [
    "## Solution 1: Fixing the Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c0db2-ae9f-403e-8c73-35033bba83bb",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98a1fc-4b00-470f-b0a7-25b9ec74e1a1",
   "metadata": {},
   "source": [
    "SMOTE, or Synthetic Minority Oversampling Technique, is a class imbalance correction technique. SMOTE works to correct class imbalance by synthetically creating new minority class datapoints, which avoids the hiccups involved with random techniques like over or undersampling. \n",
    "\n",
    "There are some limitations, like trouble translating to higher dimensions, or the possibility of adding noise to the data because it does not consider the majority class when creating synthetic minority class data points.\n",
    "\n",
    "First, let's generate the new, more balanced classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f34c15e-3679-46ba-862d-5d2873c56bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Number of Positives: 4533 vs. New Number of Positives: 10699\n",
      "Original Number of Negatives: 35665 vs. New Number of Negatives: 35665\n"
     ]
    }
   ],
   "source": [
    "oversample = over_sampling.SMOTE(sampling_strategy = 0.3)\n",
    "X_bal, y_bal = oversample.fit_resample(X, y)\n",
    "\n",
    "num_pos = sum(y) \n",
    "num_neg = len(y) - num_pos \n",
    "\n",
    "bal_num_pos = sum(y_bal)\n",
    "bal_num_neg = len(y_bal) - bal_num_pos\n",
    "\n",
    "print(f\"Original Number of Positives: {num_pos} vs. New Number of Positives: {bal_num_pos}\")\n",
    "print(f\"Original Number of Negatives: {num_neg} vs. New Number of Negatives: {bal_num_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45437d1b-b052-4f32-8426-748dd752f760",
   "metadata": {},
   "source": [
    "All we have done is inflate the number of positives so that they now constitute roughly 30% of our dataset. Let us see if this creates any improvement in model performance: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623461b3-9a74-47f2-9571-6135cb658957",
   "metadata": {},
   "source": [
    "### Testing Model post-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc6a8f0e-6411-41db-8157-d6bcd7dbc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal_train, X_bal_test, y_bal_train, y_bal_test = train_test_split(X_bal, y_bal, random_state=0, train_size = .70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9281d598-f243-4a18-bc0e-397394c63d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting balanced training data into tensors\n",
    "\n",
    "X_bal_train_tensor = df_to_tensor(X_bal_train, outcome = False)\n",
    "y_bal_train_tensor = df_to_tensor(y_bal_train, outcome = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13e48143-3e97-457d-9ffb-745b2ab41db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.5528285503387451\n",
      "Finished epoch 1, latest loss 0.4085456430912018\n",
      "Finished epoch 2, latest loss 0.37239256501197815\n",
      "Finished epoch 3, latest loss 0.2951275110244751\n",
      "Finished epoch 4, latest loss 0.26278969645500183\n",
      "Finished epoch 5, latest loss 0.24875782430171967\n",
      "Finished epoch 6, latest loss 0.22522373497486115\n",
      "Finished epoch 7, latest loss 0.19584278762340546\n",
      "Finished epoch 8, latest loss 0.15925084054470062\n",
      "Finished epoch 9, latest loss 0.14214853942394257\n",
      "Finished epoch 10, latest loss 0.12505365908145905\n",
      "Finished epoch 11, latest loss 0.10558471828699112\n",
      "Finished epoch 12, latest loss 0.11162086576223373\n",
      "Finished epoch 13, latest loss 0.10797242075204849\n",
      "Finished epoch 14, latest loss 0.09547233581542969\n",
      "Finished epoch 15, latest loss 0.07443880289793015\n",
      "Finished epoch 16, latest loss 0.07245483249425888\n",
      "Finished epoch 17, latest loss 0.08304374665021896\n",
      "Finished epoch 18, latest loss 0.08149172365665436\n",
      "Finished epoch 19, latest loss 0.07781846821308136\n",
      "Finished epoch 20, latest loss 0.0670102909207344\n",
      "Finished epoch 21, latest loss 0.08074528723955154\n",
      "Finished epoch 22, latest loss 0.07214035838842392\n",
      "Finished epoch 23, latest loss 0.07351169735193253\n",
      "Finished epoch 24, latest loss 0.08943220227956772\n",
      "Finished epoch 25, latest loss 0.06176702678203583\n",
      "Finished epoch 26, latest loss 0.073835089802742\n",
      "Finished epoch 27, latest loss 0.0636124238371849\n",
      "Finished epoch 28, latest loss 0.07008571177721024\n",
      "Finished epoch 29, latest loss 0.0697421059012413\n",
      "Finished epoch 30, latest loss 0.08199803531169891\n",
      "Finished epoch 31, latest loss 0.0611906498670578\n",
      "Finished epoch 32, latest loss 0.06918372213840485\n",
      "Finished epoch 33, latest loss 0.0852249339222908\n",
      "Finished epoch 34, latest loss 0.06705418229103088\n",
      "Finished epoch 35, latest loss 0.07992839068174362\n",
      "Finished epoch 36, latest loss 0.06711796671152115\n",
      "Finished epoch 37, latest loss 0.06230861321091652\n",
      "Finished epoch 38, latest loss 0.041341740638017654\n",
      "Finished epoch 39, latest loss 0.04456115886569023\n",
      "Finished epoch 40, latest loss 0.05035359784960747\n",
      "Finished epoch 41, latest loss 0.08466703444719315\n",
      "Finished epoch 42, latest loss 0.070810966193676\n",
      "Finished epoch 43, latest loss 0.053931158035993576\n",
      "Finished epoch 44, latest loss 0.0657045915722847\n",
      "Finished epoch 45, latest loss 0.05994463339447975\n",
      "Finished epoch 46, latest loss 0.05461772903800011\n",
      "Finished epoch 47, latest loss 0.07766091078519821\n",
      "Finished epoch 48, latest loss 0.045021042227745056\n",
      "Finished epoch 49, latest loss 0.0503276102244854\n",
      "Finished epoch 50, latest loss 0.06062248721718788\n",
      "Finished epoch 51, latest loss 0.048260435461997986\n",
      "Finished epoch 52, latest loss 0.06657339632511139\n",
      "Finished epoch 53, latest loss 0.04944591596722603\n",
      "Finished epoch 54, latest loss 0.044346924871206284\n",
      "Finished epoch 55, latest loss 0.0411938801407814\n",
      "Finished epoch 56, latest loss 0.05013865604996681\n",
      "Finished epoch 57, latest loss 0.043916989117860794\n",
      "Finished epoch 58, latest loss 0.04270321503281593\n",
      "Finished epoch 59, latest loss 0.04162830486893654\n",
      "Finished epoch 60, latest loss 0.056777630001306534\n",
      "Finished epoch 61, latest loss 0.036602847278118134\n",
      "Finished epoch 62, latest loss 0.04053790867328644\n",
      "Finished epoch 63, latest loss 0.04047560319304466\n",
      "Finished epoch 64, latest loss 0.04031522199511528\n",
      "Finished epoch 65, latest loss 0.0457155704498291\n",
      "Finished epoch 66, latest loss 0.04775281250476837\n",
      "Finished epoch 67, latest loss 0.04012362286448479\n",
      "Finished epoch 68, latest loss 0.052081432193517685\n",
      "Finished epoch 69, latest loss 0.04892539605498314\n",
      "Finished epoch 70, latest loss 0.05016559362411499\n",
      "Finished epoch 71, latest loss 0.048705700784921646\n",
      "Finished epoch 72, latest loss 0.04159091040492058\n",
      "Finished epoch 73, latest loss 0.06810341030359268\n",
      "Finished epoch 74, latest loss 0.040742166340351105\n",
      "Finished epoch 75, latest loss 0.046475257724523544\n",
      "Finished epoch 76, latest loss 0.03927917033433914\n",
      "Finished epoch 77, latest loss 0.050506383180618286\n",
      "Finished epoch 78, latest loss 0.04174792766571045\n",
      "Finished epoch 79, latest loss 0.045396849513053894\n",
      "Finished epoch 80, latest loss 0.03517657890915871\n",
      "Finished epoch 81, latest loss 0.05158674716949463\n",
      "Finished epoch 82, latest loss 0.03657311573624611\n",
      "Finished epoch 83, latest loss 0.03327406570315361\n",
      "Finished epoch 84, latest loss 0.04157617315649986\n",
      "Finished epoch 85, latest loss 0.04945070669054985\n",
      "Finished epoch 86, latest loss 0.055232200771570206\n",
      "Finished epoch 87, latest loss 0.05089172348380089\n",
      "Finished epoch 88, latest loss 0.03463376685976982\n",
      "Finished epoch 89, latest loss 0.028015315532684326\n",
      "Finished epoch 90, latest loss 0.03377984091639519\n",
      "Finished epoch 91, latest loss 0.04768471047282219\n",
      "Finished epoch 92, latest loss 0.04726581275463104\n",
      "Finished epoch 93, latest loss 0.11281478404998779\n",
      "Finished epoch 94, latest loss 0.03925536572933197\n",
      "Finished epoch 95, latest loss 0.060529351234436035\n",
      "Finished epoch 96, latest loss 0.0448455847799778\n",
      "Finished epoch 97, latest loss 0.03945915773510933\n",
      "Finished epoch 98, latest loss 0.04267806187272072\n",
      "Finished epoch 99, latest loss 0.03668125346302986\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X_bal_train_tensor), batch_size):\n",
    "        Xbatch = X_bal_train_tensor[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y_bal_train_tensor[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82192d45-9a34-4d2d-af3b-ecc6f65d5597",
   "metadata": {},
   "source": [
    "### Training Performance w/ SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40483105-f880-4b63-ae10-cbb17114ab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 92.73%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_bal_train_pred = model(X_bal_train_tensor)\n",
    "\n",
    "bal_train_classifications = y_bal_train_pred.round()\n",
    "    \n",
    "bal_train_accuracy = (bal_train_classifications == y_bal_train_tensor).float().mean()\n",
    "print(f\"Training Accuracy: {round(float(bal_train_accuracy)*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c7f1b-266b-4d4d-af61-794555653ec8",
   "metadata": {},
   "source": [
    "We observe a similar level of accuracy to our previous attempts, but given our lower loss during the training phases, I would believe this will result in better performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "25468f76-0191-45ed-9db5-474bc3ae39f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Training Precision: 89.6%\n",
      "Balanced Training Recall: 77.42%\n",
      "Balanced Training F1 Score: 0.83\n",
      "Balanced Training Specificity: 2.69%\n",
      "Balanced Training True Negative Rate (TNR): 97.31%\n",
      "Balanced Training False Negative Rate (FNR): 22.58%\n"
     ]
    }
   ],
   "source": [
    "bal_train_metrics = calculate_pos_neg(y_bal_train_pred, y_bal_train_tensor)\n",
    "bal_train_tp = bal_train_metrics[0]\n",
    "bal_train_fp = bal_train_metrics[1]\n",
    "bal_train_tn = bal_train_metrics[2]\n",
    "bal_train_fn = bal_train_metrics[3]\n",
    "            \n",
    "bal_train_precision = bal_train_tp / (bal_train_tp + bal_train_fp)\n",
    "bal_train_recall = bal_train_tp / (bal_train_tp + bal_train_fn)\n",
    "bal_train_f1 = (2 * bal_train_precision * bal_train_recall) / (bal_train_precision + bal_train_recall)\n",
    "bal_train_specificity = bal_train_fp / (bal_train_fp + bal_train_tn)\n",
    "bal_train_tnr = bal_train_tn / (bal_train_tn + bal_train_fp)\n",
    "bal_train_fnr = bal_train_fn / (bal_train_fn + bal_train_tp)\n",
    "\n",
    "print(f\"Balanced Training Precision: {round(bal_train_precision * 100, 2)}%\")\n",
    "print(f\"Balanced Training Recall: {round(bal_train_recall * 100, 2)}%\")\n",
    "print(f\"Balanced Training F1 Score: {round(bal_train_f1, 2)}\")\n",
    "print(f\"Balanced Training Specificity: {round(bal_train_specificity * 100, 2)}%\")\n",
    "print(f\"Balanced Training True Negative Rate (TNR): {round(bal_train_tnr * 100, 2)}%\")\n",
    "print(f\"Balanced Training False Negative Rate (FNR): {round(bal_train_fnr * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bf740-7ab0-408e-82fa-dc21deb4d339",
   "metadata": {},
   "source": [
    "We see a dramatic improvement in our metrics! We have a very strong positive predictor now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182df8a8-33d4-4f6e-a43c-78bc1cd6d88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
